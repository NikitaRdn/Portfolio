This task is a supervised learning exercise. More precisely we do a regression because the output is the age of a patient and as such it is continuous. In order to accomplish the task, the scikit-learn library is used. The first step is to extract the data and preprocess it. The preprocessing consists of filling the missing data with the median of that feature, removing outliers using local outlier detection, scaling all features (zero mean and unit variance), and finally selecting 200 features by looking at correlation between the feature and the output.
	After trying simple linear and polynomial regressions (reaching a score of around 0.55) more powerful algorithms were investigated. Finally, the Gradient boosting provided the best result. The number of estimators was the main hyperparameter that was tuned. It must not be too high to avoid overfitting. Plots of the training and validation sets were used to see this issue. Strangely the best score seems to happen long before what would appear as overfitting in the plot. This could be due to the difference between least square error and the r2 score. The final submission uses 750 estimators. In order to improve this result, it might be useful to look at different strategies for filling the missing data and feature selection. Maybe creating non-linear features can be useful.
